# ZED Gesture Detection

The goal of this project is to classify gestures in real-time using the ZED camera's Body_38 keypoints, which provide 3D coordinates of body joints. The primary focus is on detecting and classifying basic right-arm gestures such as swiping left, right, up, and down. The system must be capable of handling inconsistencies in frame data while ensuring smooth interpolation for missing keypoints. The classified gestures will then be used to trigger immediate actions, such as screen swiping.
